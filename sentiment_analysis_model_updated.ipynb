{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_model_updated.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/KushalVenkatesh/Sentiment_Analysis_Customer_Reviews_TestPilot/blob/master/sentiment_analysis_model_updated.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "L16NJVfs0NEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SENTIMENT ANALYSIS USING REVIEW'S STARS"
      ]
    },
    {
      "metadata": {
        "id": "HdB-KWaS0NEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#text-classification-sentiment-analysis-naive-bayes-classifier\n",
        "#referenced from the following blog\n",
        "#http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
        "import nltk.classify.util\n",
        "import collections, itertools\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import scores, sent_tokenize, word_tokenize, pos_tag, MaxentClassifier\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "from nltk.probability import FreqDist, ConditionalFreqDist\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from numpy import mean\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef\n",
        "from string import punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uimvOh0Z0NEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.seed(88)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5yxn8EG0NEy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TO EVALUATE MODELS ##"
      ]
    },
    {
      "metadata": {
        "id": "h6s_lgaL0NEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate features\n",
        "def evaluate_classifier(featx,                         \n",
        "                        negtrain,\n",
        "                        negtest,\n",
        "                        postrain, \n",
        "                        postest):     \n",
        "    \n",
        "    negtrain_feats = [(featx(w), 'neg') for w in negtrain]\n",
        "    negtest_feats  = [(featx(w), 'neg') for w in negtest]\n",
        "    postrain_feats = [(featx(w), 'pos') for w in postrain]\n",
        "    postest_feats  = [(featx(w), 'pos') for w in postest]\n",
        "    \n",
        "    trainfeats = negtrain_feats + postrain_feats\n",
        "    testfeats = negtest_feats + postest_feats    \n",
        "    trainfeats = random.sample(trainfeats, len(trainfeats))\n",
        "    testfeats = random.sample(testfeats, len(testfeats))    \n",
        "        \n",
        "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
        "    # classifier = MaxentClassifier.train(trainfeats)\n",
        "    \n",
        "    actual = []\n",
        "    predict = []\n",
        "\n",
        "    for i, (feats, label) in enumerate(testfeats):        \n",
        "            observed = classifier.classify(feats)\n",
        "            actual.append(label)\n",
        "            predict.append(observed)\n",
        "    try:\n",
        "        accuracy = accuracy_score(actual, predict)\n",
        "    except:\n",
        "        accuracy = None\n",
        "        print('Accuracy: Division by zero')\n",
        "\n",
        "    try:\n",
        "        precision = precision_score(actual, predict)\n",
        "    except:\n",
        "        precision = None\n",
        "        print('Precision: Division by zero')\n",
        "\n",
        "    try:\n",
        "        recall = recall_score(actual, predict)\n",
        "    except:\n",
        "        recall  = None\n",
        "        print('Recall: Division by zero')\n",
        "\n",
        "    try:\n",
        "        matthew = matthews_corrcoef(actual, predict)\n",
        "    except:\n",
        "        matthew = None\n",
        "        print('Matthews corr coeff: Division by zero')\n",
        "\n",
        "    return accuracy, precision, recall, matthew, classifier\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GnEfXr2w0NE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate features (include bestwords)\n",
        "def evaluate_classifier2(featx,                         \n",
        "                        negtrain,\n",
        "                        negtest,\n",
        "                        postrain, \n",
        "                        postest,\n",
        "                        bestwords):    \n",
        "    \n",
        "    negtrain_feats = [(featx(w, bestwords), 'neg') for w in negtrain]\n",
        "    negtest_feats  = [(featx(w, bestwords), 'neg') for w in negtest]\n",
        "    postrain_feats = [(featx(w, bestwords), 'pos') for w in postrain]\n",
        "    postest_feats  = [(featx(w, bestwords), 'pos') for w in postest]\n",
        "    \n",
        "    trainfeats = negtrain_feats + postrain_feats\n",
        "    testfeats = negtest_feats + postest_feats    \n",
        "    trainfeats = random.sample(trainfeats, len(trainfeats))\n",
        "    testfeats = random.sample(testfeats, len(testfeats))\n",
        "        \n",
        "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
        "    # classifier = MaxentClassifier.train(trainfeats)\n",
        "    \n",
        "    actual = []\n",
        "    predict = []\n",
        "\n",
        "    for i, (feats, label) in enumerate(testfeats):        \n",
        "            observed = classifier.classify(feats)\n",
        "            actual.append(label)\n",
        "            predict.append(observed)\n",
        "    try:\n",
        "        accuracy = accuracy_score(actual, predict)\n",
        "    except:\n",
        "        accuracy = None\n",
        "        print('Accuracy: Division by zero')\n",
        "\n",
        "    try:\n",
        "        precision = precision_score(actual, predict)\n",
        "    except:\n",
        "        precision = None\n",
        "        print('Precision: Division by zero')\n",
        "\n",
        "    try:\n",
        "        recall = recall_score(actual, predict)\n",
        "    except:\n",
        "        recall  = None\n",
        "        print('Recall: Division by zero')\n",
        "\n",
        "    try:\n",
        "        matthew = matthews_corrcoef(actual, predict)\n",
        "    except:\n",
        "        matthew = None\n",
        "        print('Matthews corr coeff: Division by zero')\n",
        "\n",
        "    return accuracy, precision, recall, matthew, classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmfAg0rM0NE3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FEATURES ##"
      ]
    },
    {
      "metadata": {
        "id": "XokKCNFZ0NE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Bag of words: All words\n",
        "def word_feats(words):\n",
        "    return dict([(word, True) for word in words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QeHx0pTh1bFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fcc86267-cb0d-45af-f06e-c9102154b5eb"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "yEO6abW_0NE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Stopword filtering\n",
        "stop_set = set(stopwords.words('english')) \n",
        "\n",
        "def stopword_filtered_word_feats(words, stopset = stop_set):\n",
        "    return dict([(word, True) for word in words if word not in stopset])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4674n8x0NE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Bigram Collocations\n",
        "def bigram_word_feats(words, score_fn = BigramAssocMeasures.chi_sq, n = 200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
        "    bigrams = bigram_finder.nbest(score_fn, n)\n",
        "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85GP9x230NE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Eliminate Low Information Features\n",
        "def get_best_words(neg_train, pos_train, best_n):\n",
        "    word_fd = FreqDist()\n",
        "    label_word_fd = ConditionalFreqDist()\n",
        "\n",
        "    for w in [word for review in neg_train for word in review]:\n",
        "        word_fd[w.lower()] += 1\n",
        "        label_word_fd['neg'][w.lower()] += 1\n",
        "\n",
        "    for w in [word for review in pos_train for word in review]:\n",
        "        word_fd[w.lower()] += 1\n",
        "        label_word_fd['pos'][w.lower()] += 1\n",
        "\n",
        "    neg_word_count = label_word_fd['neg'].N()\n",
        "    pos_word_count = label_word_fd['pos'].N()\n",
        "    total_word_count = pos_word_count + neg_word_count\n",
        "    \n",
        "    # Compute scores\n",
        "    word_scores = {}\n",
        "    for word, freq in word_fd.items():\n",
        "        pos_score = BigramAssocMeasures.chi_sq( \\\n",
        "            label_word_fd['pos'][word], \\\n",
        "            (freq, pos_word_count), \\\n",
        "            total_word_count)\n",
        "        neg_score = BigramAssocMeasures.chi_sq( \\\n",
        "            label_word_fd['neg'][word], \\\n",
        "            (freq, neg_word_count), \\\n",
        "            total_word_count)\n",
        "        word_scores[word] = pos_score + neg_score\n",
        "    \n",
        "    # Choose best score\n",
        "    best = sorted(word_scores.items(), \\\n",
        "                  key=lambda s: s[1], \\\n",
        "                  reverse=True)[:best_n]    \n",
        "    return set([w for w, s in best])\n",
        "\n",
        "# Features (words) based on best words\n",
        "def best_word_feats(words, bestwords):\n",
        "    return dict([(word, True) for word in words if word in bestwords])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7SqgutN0NFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Best words + bigram\n",
        "def best_bigram_word_feats(words, \n",
        "                           bestwords,\n",
        "                           score_fn = BigramAssocMeasures.chi_sq, \n",
        "                           n = 200):\n",
        "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
        "    bigrams = bigram_finder.nbest(score_fn, n)\n",
        "    d = dict([(bigram, True) for bigram in bigrams])\n",
        "    d.update(best_word_feats(words, bestwords))\n",
        "    return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LvKKFw0_0NFE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DEVELOP MODEL ##"
      ]
    },
    {
      "metadata": {
        "id": "luDC4HPt01C2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6b5dd6b-8111-4631-a3ee-e2296aa5b90d"
      },
      "cell_type": "code",
      "source": [
        "!ls rebtel_sentiment_analysis/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rawdata_20170620.json  rawdata_20180717.json  reviews_influxDB.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P8dRTI5G0NFG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare data "
      ]
    },
    {
      "metadata": {
        "id": "1TpYZYte0NFH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load raw data\n",
        "file_name = 'rebtel_sentiment_analysis/data/rawdata_20180717.json'\n",
        "with open(file_name) as json_data:\n",
        "    data = json.load(json_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dVM7kq5v0NFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert to dataframe\n",
        "df = pd.DataFrame(data)\n",
        "df = df.drop_duplicates()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXChMaa-0NFP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove punctuation\n",
        "import re\n",
        "import string\n",
        "\n",
        "def remove_punctuation(s):\n",
        "    s = ''.join([i for i in s if i not in frozenset(punctuation)])\n",
        "    return s\n",
        "\n",
        "rem = string.punctuation\n",
        "pattern = r\"[{}]\".format(rem)\n",
        "df['text_nopunct'] = df['text'].str.replace(pattern, ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQPtb8_j0NFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04aabc46-d257-4fa6-d05b-6cc6f8622071"
      },
      "cell_type": "code",
      "source": [
        "# Classify reviews: negative vs positive vs neutral\n",
        "# Assumptions:\n",
        "# Reviews with 1,2 stars -> negative\n",
        "# Reviews with 4,5 stars -> positive\n",
        "# Revjiews with 3 stars -> neutral\n",
        "\n",
        "df_neg = df[(df.stars == 1) | (df.stars == 2)]\n",
        "df_pos = df[(df.stars == 4) | (df.stars == 5)]\n",
        "df_neu = df[(df.stars == 3)]\n",
        "df_neg.shape, df_pos.shape, df_neu.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((721, 9), (2128, 9), (275, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "h8QOCnEe0NFZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Assumption: We focused on positive and negative reviews (discard neutral)"
      ]
    },
    {
      "metadata": {
        "id": "-E5g0l3F0NFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a962b879-6f37-4f20-cc9d-0949ce78ccef"
      },
      "cell_type": "code",
      "source": [
        "# Split reviews: positive vs negative\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "neg_words = [word_tokenize(f) for f in df_neg.text_nopunct]\n",
        "pos_words = [word_tokenize(f) for f in df_pos.text_nopunct]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GOhdlSR90NFc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split data set: developing vs validation\n",
        "neg_develop, neg_val = train_test_split(neg_words, test_size=0.25)\n",
        "pos_develop, pos_val = train_test_split(pos_words, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bljz30Zd0NFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0dc7381-bd1b-45a6-f486-15db957727ca"
      },
      "cell_type": "code",
      "source": [
        "len(neg_develop),len(neg_val), len(pos_develop),len(pos_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(540, 181, 1596, 532)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "uuDiDq5v0NFi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5-CROSS VALIDATION ##"
      ]
    },
    {
      "metadata": {
        "id": "PQPy-nRb0NFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# k-fold cross validation\n",
        "k = 5\n",
        "\n",
        "results = collections.defaultdict(dict)\n",
        "models = ['bag_of_words', 'stop_words', 'bigram', \\\n",
        "          'best_words', 'bigram_best_words']\n",
        "for model_name in models:\n",
        "    results[model_name]['accuracy'] = []\n",
        "    results[model_name]['precision'] = []\n",
        "    results[model_name]['recall'] = []\n",
        "    results[model_name]['matthew'] = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEzBZFOP0NFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "2a4bb367-0499-453c-d75b-5729235b3f1b"
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, k):\n",
        "    # Split developing dataset: training vs testing\n",
        "    neg_train, neg_test = train_test_split(neg_develop, test_size=1/k)\n",
        "    pos_train, pos_test = train_test_split(pos_develop, test_size=1/k)    \n",
        "        \n",
        "    num_train = len(neg_train) + len(pos_train)\n",
        "    num_test = len(neg_test) + len(pos_test)    \n",
        "    print(str(i) + '. Train on %d instances, test on %d instances' % \\\n",
        "          (num_train, num_test)) \n",
        "    \n",
        "    model_name = 'bag_of_words'\n",
        "    print(model_name.upper())    \n",
        "    accuracy, precision, recall, matthew, _ = evaluate_classifier(\n",
        "        word_feats,                         \n",
        "        negtrain = neg_train,\n",
        "        negtest = neg_test,\n",
        "        postrain = pos_train, \n",
        "        postest = pos_test) \n",
        "    results[model_name]['accuracy'].append(accuracy)\n",
        "    results[model_name]['precision'].append(precision)\n",
        "    results[model_name]['recall'].append(recall)\n",
        "    results[model_name]['matthew'].append(matthew)\n",
        "    \n",
        "        \n",
        "    model_name = 'stop_words'\n",
        "    print(model_name.upper())     \n",
        "    accuracy, precision, recall, matthew, _ = evaluate_classifier(\n",
        "        stopword_filtered_word_feats,                         \n",
        "        negtrain = neg_train,\n",
        "        negtest = neg_test,\n",
        "        postrain = pos_train, \n",
        "        postest = pos_test)\n",
        "    results[model_name]['accuracy'].append(accuracy)\n",
        "    results[model_name]['precision'].append(precision)\n",
        "    results[model_name]['recall'].append(recall)\n",
        "    results[model_name]['matthew'].append(matthew)\n",
        "    \n",
        "#     model_name = 'bigram'\n",
        "#     print(model_name.upper())     \n",
        "#     accuracy, precision, recall, matthew, _ = evaluate_classifier(\n",
        "#         bigram_word_feats,                         \n",
        "#         negtrain = neg_train,\n",
        "#         negtest = neg_test,\n",
        "#         postrain = pos_train, \n",
        "#         postest = pos_test) \n",
        "#     results[model_name]['accuracy'].append(accuracy)\n",
        "#     results[model_name]['precision'].append(precision)\n",
        "#     results[model_name]['recall'].append(recall)\n",
        "#     results[model_name]['matthew'].append(matthew)\n",
        "    \n",
        "    best_words = get_best_words(neg_train, pos_train, 5000)                         \n",
        "    model_name = 'best_words'    \n",
        "    print(model_name.upper())            \n",
        "    accuracy, precision, recall, matthew, _ = evaluate_classifier2(\n",
        "        best_word_feats,                        \n",
        "        negtrain = neg_train,\n",
        "        negtest = neg_test,\n",
        "        postrain = pos_train, \n",
        "        postest = pos_test,\n",
        "        bestwords = best_words) \n",
        "    results[model_name]['accuracy'].append(accuracy)\n",
        "    results[model_name]['precision'].append(precision)\n",
        "    results[model_name]['recall'].append(recall)\n",
        "    results[model_name]['matthew'].append(matthew)\n",
        "                     \n",
        "#     model_name = 'bigram_best_words'\n",
        "#     print(model_name.upper())         \n",
        "#     accuracy, precision, recall, matthew, _ = evaluate_classifier2(\n",
        "#         best_bigram_word_feats,                         \n",
        "#         negtrain = neg_train,\n",
        "#         negtest = neg_test,\n",
        "#         postrain = pos_train, \n",
        "#         postest = pos_test,\n",
        "#         bestwords = best_words)\n",
        "#     results[model_name]['accuracy'].append(accuracy)\n",
        "#     results[model_name]['precision'].append(precision)\n",
        "#     results[model_name]['recall'].append(recall)\n",
        "#     results[model_name]['matthew'].append(matthew)\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0. Train on 2136 instances, test on 0 instances\n",
            "BAG_OF_WORDS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "STOP_WORDS\n",
            "BEST_WORDS\n",
            "1. Train on 2136 instances, test on 0 instances\n",
            "BAG_OF_WORDS\n",
            "STOP_WORDS\n",
            "BEST_WORDS\n",
            "2. Train on 2136 instances, test on 0 instances\n",
            "BAG_OF_WORDS\n",
            "STOP_WORDS\n",
            "BEST_WORDS\n",
            "3. Train on 2136 instances, test on 0 instances\n",
            "BAG_OF_WORDS\n",
            "STOP_WORDS\n",
            "BEST_WORDS\n",
            "4. Train on 2136 instances, test on 0 instances\n",
            "BAG_OF_WORDS\n",
            "STOP_WORDS\n",
            "BEST_WORDS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3rsPYzK0NFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "26f47366-71bc-4d1f-d031-68ebd71b1702"
      },
      "cell_type": "code",
      "source": [
        "# Choose Best Features\n",
        "best_features = collections.defaultdict(dict)\n",
        "for model_name in models:\n",
        "    a = [x for x in results[model_name]['accuracy'] if x is not None]\n",
        "    if len(a)>0:\n",
        "        best_features[model_name]['accuracy'] = mean(a)\n",
        "        \n",
        "    p = [x for x in results[model_name]['precision'] if x is not None]\n",
        "    if len(p)>0:\n",
        "        best_features[model_name]['precision'] = mean(p)\n",
        "        \n",
        "    r = [x for x in results[model_name]['recall'] if x is not None]\n",
        "    if len(r)>0:\n",
        "        best_features[model_name]['recall'] = mean(r)\n",
        "        \n",
        "    m = [x for x in results[model_name]['matthew'] if x is not None]\n",
        "    if len(m)>0:\n",
        "        best_features[model_name]['matthew'] = mean(m)     \n",
        "    \n",
        "# Highest accuracy, precision, recall, Matthews correlation coefficient\n",
        "pd.DataFrame.from_dict({(i): best_features[i]  \n",
        "                        for i in best_features.keys()}, \n",
        "                       orient = 'index')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recall</th>\n",
              "      <th>matthew</th>\n",
              "      <th>precision</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bag_of_words</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>best_words</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stop_words</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              recall  matthew  precision  accuracy\n",
              "bag_of_words     0.0      0.0        0.0       NaN\n",
              "best_words       0.0      0.0        0.0       NaN\n",
              "stop_words       0.0      0.0        0.0       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "DMd975pI0NFq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# BEST MODEL: TRAIN ON FULL DEVELOPING DATA SET, EVALUATE ON VALIDATION SET"
      ]
    },
    {
      "metadata": {
        "id": "r6nq0SSo0NFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5234bd2f-1422-4e87-a698-98ae99f59ee1"
      },
      "cell_type": "code",
      "source": [
        "num_train = len(neg_develop) + len(pos_develop)\n",
        "num_test = len(neg_val) + len(pos_val)    \n",
        "print('Train on %d instances, test on %d instances' % (num_train, num_test)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2136 instances, test on 713 instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-zbi8qSX0NFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get best words\n",
        "best_words = get_best_words(neg_develop, pos_develop, 5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cH4Y_n_Q0NFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c1dfbd05-8827-4d97-ca2e-b9c940923875"
      },
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model_name = 'stop_words'\n",
        "print(model_name.upper()) \n",
        "\n",
        "accuracy, precision, recall, matthew, best_classifier = evaluate_classifier(\n",
        "    stopword_filtered_word_feats,                         \n",
        "    negtrain = neg_develop,\n",
        "    negtest = neg_val,\n",
        "    postrain = pos_develop, \n",
        "    postest = pos_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STOP_WORDS\n",
            "Precision: Division by zero\n",
            "Recall: Division by zero\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1030: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if pos_label not in present_labels:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "x7ORJfg00NF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f63ec9d6-e3d8-475c-c4be-cda650cdd8f9"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "if accuracy is not None: print('Accuracy: %f' % accuracy)\n",
        "if precision is not None: print('Precision: %f' % precision)\n",
        "if recall is not None: print('Recall: %f' % recall)\n",
        "if matthew is not None: print('Matthew corr coeff: %f' % matthew)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.566620\n",
            "Matthew corr coeff: 0.380511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4z8hhNsk0NF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f78886b5-b1e6-4d74-e181-bdf8f8ce300a"
      },
      "cell_type": "code",
      "source": [
        "# Most relevant features\n",
        "best_classifier.show_most_informative_features()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "                 emailed = True              neg : pos    =     46.2 : 1.0\n",
            "                  ticket = True              neg : pos    =     44.3 : 1.0\n",
            "                  refund = True              neg : pos    =     39.2 : 1.0\n",
            "                  unable = True              neg : pos    =     38.4 : 1.0\n",
            "              restricted = True              neg : pos    =     38.4 : 1.0\n",
            "                      20 = True              neg : pos    =     36.4 : 1.0\n",
            "                   worst = True              neg : pos    =     36.0 : 1.0\n",
            "                   today = True              neg : pos    =     30.5 : 1.0\n",
            "                      00 = True              neg : pos    =     30.5 : 1.0\n",
            "               contacted = True              neg : pos    =     30.1 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UpfOyL6o0NGC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L54YR3c90NGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}